# ğŸ›¡ï¸ Fraud Detection Pipeline â€” Rule-Based, Modular & Production-Inspired
A modular fraud detection pipeline simulating real-world data workflows using Airflow, dbt, and Python. Includes rule-based scoring, alerting, and dashboards. Built for analytics engineers to showcase orchestration, modeling, and platform skills.


This project simulates a real-world fraud detection pipeline, focusing on **Analytics Engineering**, **Data Orchestration**, and **Reproducible Infra**.

## ğŸ¯ Project Goal

Build an end-to-end data pipeline that detects fraudulent financial transactions using engineered features and rule-based logic. This project showcases:

- Data ingestion with Airflow
- Modeling and testing with dbt
- Risk scoring in Python
- Alerting and visualization
- Dockerized development environment

---

## ğŸ§± Tech Stack

| Tool       | Role                            |
|------------|---------------------------------|
| Airflow    | Pipeline orchestration          |
| dbt        | Modeling + testing + semantics  |
| Python     | Scoring logic + alerting        |
| MinIO      | Local S3-compatible object store|
| Postgres   | Analytical storage               |
| Metabase   | Dashboards & reporting           |
| Docker     | Reproducibility & deployment     |

---

## ğŸ—‚ï¸ Project Structure
fraud-detection-pipeline/
â”‚
â”œâ”€â”€ data/ # Source and sample data
â”œâ”€â”€ dags/ # Airflow DAGs
â”œâ”€â”€ dbt/ # dbt project files
â”œâ”€â”€ scoring/ # Scoring logic
â”œâ”€â”€ docker/ # Dockerfiles and compose
â”œâ”€â”€ metabase/ # Dashboard setup or exports
â”œâ”€â”€ notebooks/ # Optional EDA
â””â”€â”€ README.md # This file

## ğŸ§ª Pipeline Flow

### 1. **Data Layer**
- Download or generate base data
- Extend with synthetic rows
- Convert to Parquet format
- Upload to MinIO bucket (`raw/`)

### 2. **Ingestion DAG**
- Airflow fetches raw Parquet files
- Loads into DuckDB or Postgres

### 3. **Modeling (dbt)**
- Stage, clean, and enrich tables
- Create reusable marts:
    - `v_transactions`
    - `daily_user_summary`
    - `risk_exposures`
- Add tests and metrics via Semantic Layer

### 4. **Scoring (Python)**
- Read enriched tables
- Apply modular rules:
    - Transaction amount
    - Merchant risk
    - Failed login attempts
    - Account age, anomaly score, etc.
- Write `fraud_alerts` table
- Send notifications (email/Slack)

### 5. **Visualization (Metabase)**
- Connect to Postgres
- Dashboards:
    - High-risk accounts
    - Fraud trend over time
    - Merchant/category heatmaps
    - Time-to-resolution metrics

---

## ğŸš€ Deployment Plan

- All components run via `docker-compose`
- Airflow schedules ingestion + scoring
- Python scoring logic containerized separately
- Bonus: deploy scoring job as Kubernetes CronJob

---

## âœ… Status Tracker

| Task                    | Status      |
|-------------------------|-------------|
| Data download/prep      | â¬œï¸ Not started
| Airflow DAG             | â¬œï¸ Not started
| dbt models              | â¬œï¸ Not started
| Scoring logic (Python)  | â¬œï¸ Not started
| Docker setup            | â¬œï¸ Not started
| Metabase dashboards     | â¬œï¸ Not started

---

## ğŸ‘¤ Author

**Karim Tarek** â€” Data & Analytics Engineer  
_Seeking Staff Analytics Engineering roles_  
ğŸ“« [LinkedIn](https://www.linkedin.com/in/karimtarek)


